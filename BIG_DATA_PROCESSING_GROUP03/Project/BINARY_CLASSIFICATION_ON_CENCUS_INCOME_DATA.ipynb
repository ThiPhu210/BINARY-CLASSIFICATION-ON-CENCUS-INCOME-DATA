{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phân loại dữ liệu dạng bảng nhị phân với PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('D:\\Learning\\XuLyDuLieu\\spark-3.5.3-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta, datetime\n",
    "import time\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.sql.types import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tải dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('imbalanced_binary_classification').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://MSI.mshome.net:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>imbalanced_binary_classification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x201d147ead0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = \"./census.csv\"\n",
    "file_type = \"csv\"\n",
    "\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"False\"\n",
    "delimiter = \",\"\n",
    "\n",
    "\n",
    "df = spark.read.format(file_type) \\\n",
    "  .option(\"inferSchema\", infer_schema) \\\n",
    "  .option(\"header\", first_row_is_header) \\\n",
    "  .option(\"sep\", delimiter) \\\n",
    "  .load(file_location) \\\n",
    "  .toDF(\"age\", \"workClass\", \"fnlwgt\", \"education\", \"education-num\",\"marital-status\", \"occupation\", \"relationship\",\n",
    "        \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
      "|age|       workClass|fnlwgt|   education|education-num|      marital-status|       occupation| relationship|              race|   sex|capital-gain|capital-loss|hours-per-week|native-country|income|\n",
      "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
      "| 39|       State-gov| 77516|   Bachelors|           13|       Never-married|     Adm-clerical|Not-in-family|             White|  Male|        2174|           0|            40| United-States| <=50K|\n",
      "| 50|Self-emp-not-inc| 83311|   Bachelors|           13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            13| United-States| <=50K|\n",
      "| 38|         Private|215646|     HS-grad|            9|            Divorced|Handlers-cleaners|Not-in-family|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
      "| 53|         Private|234721|        11th|            7|  Married-civ-spouse|Handlers-cleaners|      Husband|             Black|  Male|           0|           0|            40| United-States| <=50K|\n",
      "| 28|         Private|338409|   Bachelors|           13|  Married-civ-spouse|   Prof-specialty|         Wife|             Black|Female|           0|           0|            40|          Cuba| <=50K|\n",
      "| 37|         Private|284582|     Masters|           14|  Married-civ-spouse|  Exec-managerial|         Wife|             White|Female|           0|           0|            40| United-States| <=50K|\n",
      "| 49|         Private|160187|         9th|            5|Married-spouse-ab...|    Other-service|Not-in-family|             Black|Female|           0|           0|            16|       Jamaica| <=50K|\n",
      "| 52|Self-emp-not-inc|209642|     HS-grad|            9|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|           0|           0|            45| United-States|  >50K|\n",
      "| 31|         Private| 45781|     Masters|           14|       Never-married|   Prof-specialty|Not-in-family|             White|Female|       14084|           0|            50| United-States|  >50K|\n",
      "| 42|         Private|159449|   Bachelors|           13|  Married-civ-spouse|  Exec-managerial|      Husband|             White|  Male|        5178|           0|            40| United-States|  >50K|\n",
      "| 37|         Private|280464|Some-college|           10|  Married-civ-spouse|  Exec-managerial|      Husband|             Black|  Male|           0|           0|            80| United-States|  >50K|\n",
      "| 30|       State-gov|141297|   Bachelors|           13|  Married-civ-spouse|   Prof-specialty|      Husband|Asian-Pac-Islander|  Male|           0|           0|            40|         India|  >50K|\n",
      "| 23|         Private|122272|   Bachelors|           13|       Never-married|     Adm-clerical|    Own-child|             White|Female|           0|           0|            30| United-States| <=50K|\n",
      "| 32|         Private|205019|  Assoc-acdm|           12|       Never-married|            Sales|Not-in-family|             Black|  Male|           0|           0|            50| United-States| <=50K|\n",
      "| 40|         Private|121772|   Assoc-voc|           11|  Married-civ-spouse|     Craft-repair|      Husband|Asian-Pac-Islander|  Male|           0|           0|            40|             ?|  >50K|\n",
      "| 34|         Private|245487|     7th-8th|            4|  Married-civ-spouse| Transport-moving|      Husband|Amer-Indian-Eskimo|  Male|           0|           0|            45|        Mexico| <=50K|\n",
      "| 25|Self-emp-not-inc|176756|     HS-grad|            9|       Never-married|  Farming-fishing|    Own-child|             White|  Male|           0|           0|            35| United-States| <=50K|\n",
      "| 32|         Private|186824|     HS-grad|            9|       Never-married|Machine-op-inspct|    Unmarried|             White|  Male|           0|           0|            40| United-States| <=50K|\n",
      "| 38|         Private| 28887|        11th|            7|  Married-civ-spouse|            Sales|      Husband|             White|  Male|           0|           0|            50| United-States| <=50K|\n",
      "| 43|Self-emp-not-inc|292175|     Masters|           14|            Divorced|  Exec-managerial|    Unmarried|             White|Female|           0|           0|            45| United-States|  >50K|\n",
      "+---+----------------+------+------------+-------------+--------------------+-----------------+-------------+------------------+------+------------+------------+--------------+--------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'workClass',\n",
       " 'fnlwgt',\n",
       " 'education',\n",
       " 'education-num',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'capital-gain',\n",
       " 'capital-loss',\n",
       " 'hours-per-week',\n",
       " 'native-country',\n",
       " '>50K']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = df.withColumn('>50K', F.when(df.income == '<=50K', 0).otherwise(1))\n",
    "df = df.drop('income')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    " 'workClass',\n",
    " 'education',\n",
    " 'marital-status',\n",
    " 'occupation',\n",
    " 'relationship',\n",
    " 'race',\n",
    " 'sex',\n",
    " 'hours-per-week',\n",
    " 'native-country',\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml.classification import (DecisionTreeClassifier, GBTClassifier, RandomForestClassifier)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
    "    for c in categorical_columns]\n",
    "encoders = [OneHotEncoder(dropLast=False,inputCol=indexer.getOutputCol(),\n",
    "            outputCol=\"{0}_encoded\".format(indexer.getOutputCol())) \n",
    "    for indexer in indexers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_encoded = [encoder.getOutputCol() for encoder in encoders]\n",
    "numerical_columns = ['age', 'education-num', 'capital-gain', 'capital-loss']\n",
    "inputcols = categorical_encoded + numerical_columns\n",
    "assembler = VectorAssembler(inputCols=inputcols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, workClass: string, fnlwgt: int, education: string, education-num: int, marital-status: string, occupation: string, relationship: string, race: string, sex: string, capital-gain: int, capital-loss: int, hours-per-week: int, native-country: string, >50K: int, workClass_indexed: double, education_indexed: double, marital-status_indexed: double, occupation_indexed: double, relationship_indexed: double, race_indexed: double, sex_indexed: double, hours-per-week_indexed: double, native-country_indexed: double, workClass_indexed_encoded: vector, education_indexed_encoded: vector, marital-status_indexed_encoded: vector, occupation_indexed_encoded: vector, relationship_indexed_encoded: vector, race_indexed_encoded: vector, sex_indexed_encoded: vector, hours-per-week_indexed_encoded: vector, native-country_indexed_encoded: vector, features: vector]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=indexers + encoders+[assembler])\n",
    "model = pipeline.fit(df)\n",
    "transformed = model.transform(df)\n",
    "display(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = transformed.select('features', '>50K')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Khai bao model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "# Random Forests\n",
    "# Gradient Boosted Trees\n",
    "\n",
    "dtc = DecisionTreeClassifier(labelCol='>50K', featuresCol='features')\n",
    "\n",
    "rfc = RandomForestClassifier(numTrees=150, labelCol='>50K', featuresCol='features')\n",
    "\n",
    "gbt = GBTClassifier(labelCol='>50K', featuresCol='features', maxIter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39100\n",
      "9742\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "train_data, test_data = final_data.randomSplit([0.8,0.2], seed=623)\n",
    "print(train_data.count())\n",
    "print(test_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_preds = dtc_model.transform(test_data)\n",
    "rfc_preds = rfc_model.transform(test_data)\n",
    "gbt_preds = gbt_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval = BinaryClassificationEvaluator(labelCol='>50K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTC AUC:\n",
      "0.6044418969198606\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree evaluation metric\n",
    "print('DTC AUC:')\n",
    "print(my_eval.evaluate(dtc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC AUC:\n",
      "0.8914442213223257\n"
     ]
    }
   ],
   "source": [
    "# Random Forest evaluation metric\n",
    "print('RFC AUC:')\n",
    "print(my_eval.evaluate(rfc_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT AUC:\n",
      "0.9056879327977847\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Tree evaluation metric\n",
    "print('GBT AUC:')\n",
    "print(my_eval.evaluate(gbt_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Cải thiện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxDepth, [2, 4, 6])\n",
    "             .addGrid(gbt.maxBins, [20, 40, 60])\n",
    "             .addGrid(gbt.maxIter, [10, 20, 30, 40])\n",
    "             .build())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_cross_validation(estimator, paramGrid, evaluator, train_data, numFolds=5):\n",
    "    metrics = []\n",
    "    splits = train_data.randomSplit([1.0 / numFolds] * numFolds, seed=623)\n",
    "\n",
    "    for i in range(numFolds):\n",
    "        test_fold = splits[i]\n",
    "        train_fold = train_data.subtract(test_fold)\n",
    "\n",
    "        for param_map in paramGrid:\n",
    "            model = estimator.copy(param_map).fit(train_fold)\n",
    "            predictions = model.transform(test_fold)\n",
    "            metric = evaluator.evaluate(predictions)\n",
    "            metrics.append((param_map, metric, i))\n",
    "    return metrics\n",
    "\n",
    "metrics = custom_cross_validation(gbt, paramGrid, my_eval, train_data, numFolds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           param_map    metric  fold\n",
      "0  {GBTClassifier_12dc90b440e3__maxDepth: 2, GBTC...  0.890046     0\n",
      "1  {GBTClassifier_12dc90b440e3__maxDepth: 2, GBTC...  0.895798     0\n",
      "2  {GBTClassifier_12dc90b440e3__maxDepth: 2, GBTC...  0.899908     0\n",
      "3  {GBTClassifier_12dc90b440e3__maxDepth: 2, GBTC...  0.902037     0\n",
      "4  {GBTClassifier_12dc90b440e3__maxDepth: 2, GBTC...  0.890975     0\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame(metrics, columns=[\"param_map\", \"metric\", \"fold\"])\n",
    "print(metrics_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. So sánh các phiên bản và đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold                                          0         1         2         3  \\\n",
      "param_map_simplified                                                            \n",
      "maxDepth: 2, maxBins: 20, maxIter: 10  0.890046  0.881755  0.884905  0.885758   \n",
      "maxDepth: 2, maxBins: 20, maxIter: 20  0.895798  0.890808  0.891459  0.892752   \n",
      "maxDepth: 2, maxBins: 20, maxIter: 30  0.899908  0.894674  0.895140  0.895918   \n",
      "maxDepth: 2, maxBins: 20, maxIter: 40  0.902037  0.895899  0.896351  0.897342   \n",
      "maxDepth: 2, maxBins: 40, maxIter: 10  0.890975  0.883220  0.887663  0.887862   \n",
      "\n",
      "fold                                          4  \n",
      "param_map_simplified                             \n",
      "maxDepth: 2, maxBins: 20, maxIter: 10  0.893385  \n",
      "maxDepth: 2, maxBins: 20, maxIter: 20  0.901065  \n",
      "maxDepth: 2, maxBins: 20, maxIter: 30  0.904179  \n",
      "maxDepth: 2, maxBins: 20, maxIter: 40  0.905501  \n",
      "maxDepth: 2, maxBins: 40, maxIter: 10  0.895793  \n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Hàm để chuyển đổi param_map từ đối tượng Param thành dictionary\n",
    "def extract_param_map(param_map):\n",
    "    simplified = {}\n",
    "    for param, value in param_map.items():\n",
    "        param_name = param.name if hasattr(param, 'name') else str(param)\n",
    "        simplified[param_name] = value\n",
    "    return simplified\n",
    "\n",
    "metrics_df[\"param_map\"] = metrics_df[\"param_map\"].apply(extract_param_map)\n",
    "\n",
    "# Hàm chuyển đổi param_map thành chuỗi dễ đọc cho biểu đồ\n",
    "def simplify_param_map(param_map):\n",
    "    simplified = \", \".join(f\"{k}: {v}\" for k, v in param_map.items())\n",
    "    return simplified\n",
    "\n",
    "metrics_df[\"param_map_simplified\"] = metrics_df[\"param_map\"].apply(simplify_param_map)\n",
    "grouped = metrics_df.groupby([\"param_map_simplified\", \"fold\"])[\"metric\"].mean().reset_index()\n",
    "\n",
    "pivot_table = grouped.pivot(index=\"param_map_simplified\", columns=\"fold\", values=\"metric\")\n",
    "\n",
    "print(pivot_table.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.cm.viridis(np.linspace(0, 1, len(pivot_table)))\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(12, 8))\n",
    "for idx, (param_map, values) in enumerate(pivot_table.iterrows()):\n",
    "    plt.plot(values.index, values.values, marker=\"o\", label=param_map, color=colors[idx])\n",
    "plt.title(\"Biểu đồ thể hiện đánh giá giữa các biến thể mô hình tùy chỉnh tham số\", fontsize=16)\n",
    "plt.xlabel(\"Bộ Train\", fontsize=14)\n",
    "plt.ylabel(\"Thông số đánh giá AUC\", fontsize=14)\n",
    "plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "plt.legend(title=\"Tham số tùy chỉnh\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình Gradient Boosted Tree (GBT) cho hiệu quả tốt nhất\n",
    "\n",
    "Trong bước cross-validate, chúng ta sử dụng **Gradient Boosted Tree (GBT)**, mô hình đã cho kết quả tốt nhất khi thử nghiệm trên 3 mô hình Decision Tree, Random Forest, Gradient Boosted Tree. Qua việc điều chỉnh các tham số của mô hình, chúng ta đã tìm ra bộ tham số tối ưu giúp mô hình đạt được hiệu quả tốt nhất.\n",
    "\n",
    "##### Bộ tham số tối ưu\n",
    "\n",
    "Mô hình GBT hoạt động hiệu quả nhất khi sử dụng các giá trị sau:\n",
    "\n",
    "- **maxDepth** = 6: Độ sâu tối đa của cây. Với giá trị này, mô hình có thể học được các mối quan hệ phức tạp trong dữ liệu mà không bị overfitting.\n",
    "- **maxBins** = 60: Số lượng bin tối đa để phân chia các đặc trưng liên tục. \n",
    "- **maxIter** = 40: Số vòng lặp tối đa để huấn luyện mô hình. Đây là số lần mô hình cập nhật và cải thiện các cây trong quá trình huấn luyện.\n",
    "\n",
    "##### Kết quả\n",
    "\n",
    "Với bộ tham số này, mô hình đã cho kết quả tối ưu trong việc dự đoán, đạt được giá trị **AUC (Area Under Curve)** cao nhất, giúp xác định hiệu quả dự đoán của mô hình.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End Spark Session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
